\documentclass[11pt,a4paper]{article}
\pagestyle{headings}
%% link style
\usepackage{hyperref,color}
\definecolor{Red}{rgb}{0.5,0,0}
\definecolor{Blue}{rgb}{0,0,0.5}
  \hypersetup{%
    hyperindex = {true},
    colorlinks = {true},
    linktocpage = {true},
    plainpages = {false},
    linkcolor = {Blue},
    citecolor = {Blue},
    urlcolor = {Red},
    pdfstartview = {FitH},
    pdfpagemode = {UseOutlines},
    pdfview = {XYZ null null null}
  }
%% custom markup
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\let\code=\texttt
\let\proglang=\textsf
\def\ihacres{\textsc{ihacres}}
\def\Ihacres{\textsc{Ihacres}}
%% box the figures
\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}

\title{Hydromad Tutorial}
\author{Felix Andrews\\The Australian National University}

%\VignetteIndexEntry{Getting started, reading in data and fitting a model}
%\VignettePackage{hydromad}

\begin{document}

\SweaveOpts{engine=R,eps=FALSE,echo=FALSE,prefix.string=figs/tutorial}

<<preliminaries, echo=FALSE, results=hide>>=
if (!file.exists("figs")) dir.create("figs")
library(hydromad)
library(xtable)
ltheme <- canonical.theme("pdf")
ltheme$strip.background$col <- grey(7/8)
ltheme$strip.shingle$col <- grey(6/8)
ltheme$fontsize = list(text = 11)
lattice.options(default.theme = ltheme) ## set as default
ps.options(pointsize = 11)
options(width = 60, continue = " ", digits = 3)
set.seed(0)
@

\maketitle

\section{Introduction}

The \pkg{hydromad} package is designed for hydrological modelling and
associated data analysis. It is focussed on a \emph{top-down},
spatially lumped, empirical approach to environmental hydrology.  In
practice the emphasis is on models of rainfall runoff in catchments
(watersheds). Such models predict streamflow from time series of
areal rainfall and temperature or potential evapo-transpiration. They
can be calibrated to time series of observed data.

As \emph{spatially lumped} models, they do not explicitly represent
spatial variation over the catchment area. In particular, the standard
formulations do not attempt to model effects of changes in land
cover. These models are usually calibrated to a period of observed
streamflow, and the parameters defining the modelled relationship
between rainfall, evaporation and flow are assumed to be
\emph{stationary} in this period.

The modelling framework in the \pkg{hydromad} package is based on the
two-component \ihacres{} structure: (1) a \emph{soil moisture
  accounting} (SMA) module; and (2) a \emph{routing} or \emph{unit
  hydrograph} module (Figure \ref{fig:ihacres-framework}). The SMA
model converts rainfall and temperature into \emph{effective
  rainfall} --- the amount of rainfall which eventually reaches the
catchment outlet as streamflow (i.e. that which is not lost as
evaporation etc). The routing module converts effective rainfall into
streamflow, which amounts to defining the peak response and shape of
the recession curve. It is usually a linear transfer function, which
can be as simple as a single exponential recession (i.e. constant
decay rate), although variants with non-linearities are also
available.

\begin{figure}[hbpt!]
\begin{center}
\setkeys{Gin}{width=0.9\textwidth}
<<ihacres-framework, fig=TRUE, width=6, height=1>>=
library(grid)
## framework diagram structure:
## --> |box| --> |box| -->
grid.newpage()
pushViewport(viewport(gp = gpar(fontsize = 10)))
arr <- arrow(length = unit(1, "char"))
## first arrows: rainfall and evaporation (inputs)
grid.lines(y = 0.75, x = c(0.0, 0.2), arrow = arr)
grid.lines(y = 0.5, x = c(0.0, 0.2), arrow = arr)
grid.lines(y = 0.25, x = c(0.0, 0.2), arrow = arr, gp = gpar(lty=2))
grid.text(y = 0.75, x = 0.1, label = "rainfall \n")
grid.text(y = 0.5, x = 0.1, label = "temp. / PET \n")
grid.text(y = 0.25, x = 0.1, label = "other inputs \n")
## first box: loss module
grid.rect(x = 0.3, width = 0.2, height = 0.9)
grid.text(x = 0.3, label = "Soil Moisture\nAccounting (SMA)\nmodel")
## second arrow: effective rainfall
grid.lines(y = 0.5, x = c(0.4, 0.6), arrow = arr)
grid.text(y = 0.5, x = 0.5, label = "effective\n rainfall")
## second box: routing module
grid.rect(x = 0.7, width = 0.2, height = 0.9)
grid.text(x = 0.7, label = "(unit hydrograph)\n routing model")
## third arrow: streamflow (output)
grid.lines(y = 0.5, x = c(0.8, 1.0), arrow = arr)
grid.text(y = 0.5, x = 0.9, label = "streamflow \n")
upViewport()
@
\caption{\label{fig:ihacres-framework}
  The modelling framework in the \pkg{hydromad} package (the
  \ihacres{} structure). 
}
\end{center}
\end{figure}

The \pkg{hydromad} package is intended for:
\begin{itemize}
\item defining and fitting spatially-lumped hydrological models to
  observed data;
\item simulating these models, including model state variables and
  component flow separation.
\item evaluating and comparing these models: summarising performance
  by different measures and over time, using graphical displays
  (hydrograph, flow duration curve, residuals, etc) and statistics;
\item integration with other types of data analysis and model analysis
  in \proglang{R}, including sensitivity and uncertainty analyis.
\end{itemize}

This tutorial describes how to get started with the \pkg{hydromad}
\proglang{R} package. It covers the basics of reading data in from
files, converting it into the appropriate format, and fitting and
analysing a simple model.

The example we will look at is the Cotter River catchment at Gingera
(gauge 410730) in the Australian Capital Territory, Australia. This is
a 148 km$^2$ catchment managed for urban water supply. Areal rainfall
was estimated from several rain gauges operated by the Bureau of
Meteorology and EcoWise. The temperature records come from Canberra
Airport.

Once you have \proglang{R}
running\footnote{A Windows \proglang{R} installer is available from
  \url{http://cran.ms.unimelb.edu.au/bin/windows/base/release.htm}}
and have installed the \pkg{hydromad} package\footnote{at this beta
development stage, you will need to ask Felix how to do this.}, you
can load it:
<<load-package, echo=TRUE>>=
library(hydromad)
@

\section{Input data}

The required input data files for this tutorial are included with the
\pkg{hydromad} package, in the \code{doc} directory. Note that the
processed data is available directly in \proglang{R} -- just type
\code{data(Cotter)} -- but we will read it from text files as an
exercise. If you already know how to import and handle time series in
R, you could skip this section.

A few simple steps are required to import and convert the data into a
usable form: extracting dates from the files, converting streamflow
from ML/day to mm/day, handling missing data values, and aligning the
three time series in a common time period.

Let's first view the content of one of the input files.
Set the working directory to where the data file is:
<<view-files, echo=TRUE, eval=FALSE>>=
setwd(system.file("doc", package = "hydromad"))
file.show("pq_cotter.csv")
@
<<view-files-script, echo=FALSE>>=
cat(readLines("pq_cotter.csv", n = 5), "...", sep = "\n")
@

There is no header in the file, but we know that the columns represent
rainfall (P), streamflow (Q) and date of observation. The temperature
file is similar. Knowing the format and columns we can use
\code{read.table} to import the data:
<<read-files, echo=TRUE>>=
## rain and flow data
pqdat <- read.table("pq_cotter.csv", sep = ",",
                    col.names = c("P", "Q", "Date"), as.is = TRUE)
## temperature data
tdat <- read.table("t_cotter.csv", sep = ",",
                   col.names = c("T", "Date"), as.is = TRUE)
@
and view the structure of the resulting data frames:
<<view-str, echo=TRUE>>=
str(pqdat)
str(tdat)
@

So far, the \code{Date} columns are only text; \proglang{R} does not
know they are dates. We need to specify the date format, where
\code{\%d} is day, \code{\%m} is month number, \code{\%b} is month
name, \code{\%Y} is four-digit year and \code{\%y} is two-digit year
(see \code{?strptime}).
<<convert-dates, echo=TRUE>>=
pqdat$Date <- as.Date(pqdat$Date, "%d/%m/%Y")
tdat$Date <- as.Date(tdat$Date, "%d/%m/%Y")
@

If the day, month and year were in separate columns of the file, with
names \code{"day"}, \code{"mon"} and \code{"yr"} then you would do
something like:
<<convert-dates-from-columns, echo=TRUE, eval=FALSE>>=
pqdat$Date <- with(pqdat, as.Date(ISOdate(yr, mon, day)))
@

Negative values (-99) in the \emph{pq} input file represent missing
data; in \proglang{R} they should be set to the special value
\code{NA}.  Also, some dates in the temperature file are blank, and
need to be removed.
<<missing-values, echo=TRUE>>=
pqdat$P[pqdat$P < 0] <- NA
pqdat$Q[pqdat$Q < 0] <- NA
tdat <- subset(tdat, !is.na(Date))
@

The \pkg{hydromad} model fitting functions require that rainfall and
streamflow are given in the same units, typically mm / day. The
streamflow data in our input file is measured in ML / day, so we need
to convert it, supplying the catchment area of 148 km$^2$.
<<convert-to-mm, echo=TRUE>>=
pqdat$Q <- convertFlow(pqdat$Q, from = "ML", area.km2 = 148)
@

For simple applications, when the data series are already
synchronised, this data frame (or matrix) format may be enough.
However, there are benefits in working with actual \emph{time series}
objects: because they handle observation times, they allow powerful
merging, treatment of missing values, rolling averages and other
functions. While \proglang{R} has a built-in structure for regular
time series (\code{ts}), these do not handle specific dates or times,
only index numbers. It is recommended to work with \code{zoo} objects
(using the \pkg{zoo} package).\footnote{\pkg{zoo} objects are a
  generalisation of \code{ts} objects and in many cases can be used in
  the same way; see \code{vignette("zoo")}.}

<<zoo-objects, echo=TRUE>>=
library(zoo)
tsPQ <- zoo(pqdat[,1:2], pqdat$Date, frequency = 1)
tsT <- zoo(tdat[,1], tdat$Date, frequency = 1)
@

We can now merge the time series together into a final dataset.  Note
that the \pkg{hydromad} package expects temperature or
evapo-transpiration data to be called \code{E}, not
\code{T}.\footnote{This avoids name conflicts since in \proglang{R},
  \code{T} is a shorthand for \code{TRUE}.}
<<zoo-merge, echo=TRUE>>=
Cotter <- merge(tsPQ, E = tsT, all = FALSE)
@

Print the first few rows (the \emph{head}) of the time series, to
check that everything looks OK:

<<zoo-head, echo=TRUE>>=
head(Cotter, 6)
range(time(Cotter))
@

This shows that the rainfall data has missing values at the
beginning. At the other end of the series, Streamflow data is missing.
This will not cause a problem, but let us tidy it up anyway:

<<zoo-na-trim, echo=TRUE>>=
Cotter <- na.trim(Cotter)
@

The final dataset extends from \Sexpr{start(Cotter)} to
\Sexpr{end(Cotter)}, and is shown in Figure \ref{fig:dataplot} and
Table \ref{tab:datasumm}:

<<datasummary-code, echo=TRUE, eval=FALSE>>=
summary(Cotter)
@

<<datasummary, results=tex>>=
summ <- numericSummary(Cotter)
xtable(summ, caption="Data summary.
P = precipitation (mm/day), E = temperature (deg. C), Q = streamflow (mm/day).",
	label="tab:datasumm")
@


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot the raw (daily) time series:}
<<rawdataplot-code, echo=TRUE, eval=FALSE>>=
xyplot(Cotter)
@
  \emph{To plot a section of the time series:}
<<rawdataplot-code, echo=TRUE, eval=FALSE>>=
xyplot(Cotter, xlim = as.Date(c("1974-01-01","1975-01-01")))
@
  \emph{And to plot the time series aggregated to a monthly time step:}
<<dataplot-code, echo=TRUE, results=hide>>=
monthlyPQE <- aggregate(Cotter, as.yearmon, mean)
xyplot(monthlyPQE,
       screens = c("Streamflow (mm/day)", "Areal rain (mm/day)", "Temperature (deg. C)"),
       xlab = NULL)
@
<<dataplot, fig=TRUE, width=6, height=5>>=
print(trellis.last.object())
rm(monthlyPQE)
@
\caption{\label{fig:dataplot} Input data, averaged over months. }
\end{center}
\end{figure}


\section{Data checking}

In a real data analysis problem, data checking is a central
issue. However, as this document aims to introduce the core modelling
functions, only one simple check will be demonstrated here.

Table \ref{tab:datasumm} shows the mean and quartiles of each input
data series. One measure that is of key interest in hydrology is the
\emph{runoff ratio}, the proportion of the rainfall which flows out of
the catchment. In a simple case this is just \code{sum(Q) / sum(P)},
but as we have missing values, we should only compare the common
observations:

<<runoff-ratio, echo=TRUE>>=
ok <- complete.cases(Cotter[,1:2])
with(Cotter, sum(Q[ok]) / sum(P[ok]))
@ 

This figure is within the range we would expect, so we probably have
the right data series and units.

See \code{vignette("dataChecking", package = "hydromad")} (\emph{under
  construction}) for more on this topic, including analysing changes
in the runoff ratio over time, and changes in cross correlation over
time.


\section{Calibration Periods}

Let us define some calibration periods. The streamflow in each of
these periods is shown in Figure \ref{fig:calperiodsplot}.
<<define-periods, echo=TRUE>>=
ts70s <- window(Cotter, start = "1970-01-01", end = "1979-12-31")
ts80s <- window(Cotter, start = "1980-01-01", end = "1989-12-31")
ts90s <- window(Cotter, start = "1990-01-01", end = "1999-12-31")
@

\begin{figure}[hpbt]
\begin{center}
  \emph{To plot one streamflow period:}
<<oneperiodplot-code, echo=TRUE, eval=FALSE>>=
xyplot(ts90s$Q)
@
  \emph{To plot log-transformed streamflow in one period:}
<<oneperiodlogplot-code, echo=TRUE, eval=FALSE>>=
xyplot(log10(ts90s$Q), type = c("l","g"))
@
  \emph{And to plot multiple periods on log scale:}
<<calperiodsplot-code, echo=TRUE, results=hide>>=
#cuts <- as.Date(c("1970-01-01", "1980-01-01",
#                  "1990-01-01", "2000-01-01"))
#dates <- time(Cotter)
#Q <- coredata(Cotter$Q)
#xyplot(Q ~ dates | cut(dates, cuts), type = c("l", "g"),
#       scales = list(x = "sliced", y = list(log = TRUE)),
#       layout = c(1, 3))
xyplot(list(the70s = ts70s$Q, the80s = ts80s$Q, the90s = ts90s$Q),
       scales = list(y = list(log = TRUE)), type = c("l", "g"),
       layout = c(1,3))
@
<<calperiodsplot, fig=TRUE, height=8>>=
print(trellis.last.object())
@
\caption{\label{fig:calperiodsplot} Streamflow data in each of the
  chosen calibration periods. }
\end{center}
\end{figure}

In the next section, a model will be fitted to the data in one calibration
period. It will then be applied to the other periods to
cross-check model performance.


\section{Model Specification}

A \code{hydromad} object encapsulates the chosen model form, parameter
values (or ranges of values), as well as results. The model form is
divided into two components: SMA (Soil Moisture Accounting) and
routing. Additionally, a specification can be given for fitting the
routing component (\code{rfit}). If given, this is applied
automatically to fit the routing component after the SMA parameters
have been specified.

When we first set up the model, most of the parameters are not
uniquely specified, but rather have a range of possible values. These
defaults are taken from \code{hydromad.options()}, and they can be
over-ridden by arguments to the \code{hydromad} function.

A good starting point is the classic \ihacres{} model of
Jakeman and Hornberger (1993), which is a Soil Moisture Accounting
model referred to here as \code{"cwi"} (Catchment Wetness Index). The
routing component is a Unit Hydrograph composed of exponential
components, a structure referred to here as \code{"expuh"}.

When a model structure is specified, default parameter ranges for
the given SMA model are applied:

<<model, echo=TRUE>>=
cotterMod <- hydromad(ts90s, sma = "cwi", routing = "expuh")
print(cotterMod)
@

With this model specification, we can choose to calibrate the model in
various ways, or to simulate from the specified parameter space, or to
run sensitivity or uncertainty analysis.

\subsection{Calibration}

Currently implemented calibration methods include simple sampling
schemes (\code{fitBySampling}), Newton and Simplex methods with
multistart or presampling (\code{fitByOptim}) and the more
sophisticated Shuffled Complex Evolution (\code{fitBySCE}) and
Differential Evolution (\code{fitByDE}) methods.

The objective function can be specified as the \code{objective}
argument to these functions, or by setting
\code{hydromad.options(objective = )}.  It is given as an R formula (a
chunk of \proglang{R} code) which may refer to the values \code{Q} and
\code{X}, representing observed and modelled flow, respectively. For
more advanced use it may also refer to \code{U} (modelled effective
rainfall), and more generally it may refer to \code{model}, and so may
extract other items of data, etc.

Here we use the default, which is a weighted sum of the $R^2$ of
square-root transformed data, and the relative bias:
<<obj-fun>>=
hydromad.getOption("objective")
@

The \code{fitStat} function implements a generalisation of the
familiar $R^2$ (coefficient of determination) statistic.  The exponent
applied to the equation is specied as argument \code{p}, so if \code{p
  = 2}, as it is by default, then it is indeed $R^2$:

\begin{equation}
  \mathrm{fitStat} = 1 - \frac{ \sum |Q_* - X_*|^p }{ \sum |Q_* - \mathrm{E}(Q_*)|^p }
\end{equation}

where $Q$ and $X$ are the observed and modelled values. Subscript $*$
denotes transformed data, and the transform can be specified. Here we
use the square root. See \code{?summary} for more examples.

The unit hydrograph module in \ihacres{} is a linear \emph{transfer
  function}, i.e. a set of exponentially receding stores, which may be
in a parallel or series configuration.

We will specify a \emph{second-order} transfer function for the unit
hydrograph, which can be interpreted as two stores in parallel:
``quick'' flow and ``slow'' flow. This model structure often works
well and is conceptually attractive. Its notation is $(n=2, m=1)$.

The model is calibrated using the \code{fitByOptim} function, which
performs parameter sampling over the pre-specified ranges, selecting
the best of these, and finally runs an optimisation algorithm to
improve the result locally.

<<model-fit, echo=TRUE>>=
cotterMod <- update(cotterMod, rfit = list("sriv", order = c(n=2, m=1)))
cotterFit <- fitByOptim(cotterMod)
@

See the help pages \code{help("hydromad")} and
\code{help("fitByOptim")} for details of some of the options
available.


\section{Model Output}

Now that we have an object representing a calibrated model, what can
we do with it? There are many standard \proglang{R} functions which
have methods for \code{hydromad} objects, which allow one to:

\begin{description}
\item[view model info] \code{print()}, \code{summary()}, and
  \code{objFunVal()}. 
\item[extract parameter values] \code{coef()}.
\item[access data] \code{fitted()}, \code{residuals()}, and
  \code{observed()}. These exclude the warm-up period by default.
\item[run with new data] \code{update()} or \code{predict()}.
\item[simulate from parameter ranges] \code{simulate()}.
\item[plot the hydrograph] \code{xyplot()}.
\item[plot flow duration curve] \code{qqmath()}.
\end{description}

For details, see the examples below, the user manual, and the help
page of each function.\footnote{Note that to get help for generic
  functions it is necessary to specify the method for \code{hydromad}
  objects: e.g. \code{?predict.hydromad} or \code{?xyplot.hydromad}.}
The help pages are also available from the web site
\url{http://hydromad.catchment.org/}.

Most basically, one can extract the modelled streamflow time series
with the function \code{fitted()}, and this can of course be used with
any of \proglang{R}'s library of analysis functions. A quick way to
view the modelled and observed streamflow time series together is to
call \code{xyplot()} on the model object, as in Figure
\ref{fig:obs-mod-plot}. Figures \ref{fig:print-hydromad} and
\ref{fig:summary-hydromad} also show the output from calling the
functions \code{print()} and \code{summary()} on the model object.

\begin{figure}[hpbt]
\begin{center}
<<obs-mod-plot-the70s-code, echo=TRUE, results=hide>>=
xyplot(cotterFit, with.P = TRUE)
@
<<obs-mod-plot-the70s, fig=TRUE, height=4>>=
print(trellis.last.object())
@
\caption{\label{fig:obs-mod-plot} Observed vs modelled
  streamflow in the calibration period. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
    \emph{To display information and parameters of a model:}
<<print-model, echo=TRUE>>=
print(cotterFit)
@
\caption{\label{fig:print-hydromad}
  Printing a model to view its parameter values. Note one can get hold of
the parameter values using
\code{coef(cotterFit)} or
\code{coef(cotterFit, which = "routing")} (for the unit hydrograph module).
}
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
\emph{To display basic performance statistics for a model:}
<<summary-model-code, echo=TRUE>>=
summary(cotterFit)
@
\caption{\label{fig:summary-hydromad}
  Calculating basic performance statistics for a model. The
  \code{summary} function actually returns a list, containing the
  values of various performance statistics. }
\end{center}
\end{figure}


\section{Model Simulation}

We can simulate this model on the other periods using the \code{update} function:
<<update-newdata, echo=TRUE>>=
sim70s <- update(cotterFit, newdata = ts70s)
sim80s <- update(cotterFit, newdata = ts80s)
simAll <- update(cotterFit, newdata = Cotter)
@

For \emph{verification} purposes, we would like to calculate
performance statistics for the whole dataset but excluding the
calibration period. The easiest way to do this is to set the observed
streamflow data in the calibration period to \code{NA} (missing), and
then run the simulation:
<<verfication-period-one, echo=TRUE>>=
tsVerif <- Cotter
tsVerif$Q[time(ts90s)] <- NA
simVerif <- update(cotterFit, newdata = tsVerif)
@

It is convenient to group these models together into a \code{runlist},
which is just a list of fitted models:
<<runlist, echo=TRUE>>=
allMods <- runlist(calibration = cotterFit, sim70s, sim80s, simVerif)
@

The predicted time series (hydrograph) and cumulative distribution
(flow duration curve) can be generated as in Figures
\ref{fig:obs-mod-plots} and \ref{fig:fdc-plot}.

\begin{figure}[hpbt]
\begin{center}
<<obs-mod-plots-code, echo=TRUE, results=hide>>=
xyplot(allMods[2:3] scales = list(y = list(log = TRUE)))
@
<<obs-mod-plots, fig=TRUE>>=
print(trellis.last.object())
@
\caption{\label{fig:obs-mod-plots} Observed vs modelled
  streamflow in validation periods. }
\end{center}
\end{figure}


\begin{table}[hpbt]
\begin{center}
<<mod-cal-stats-table-code, echo=TRUE, eval=FALSE>>=
summary(allMods)
@
<<mod-cal-stats-table, results=tex>>=
perfstats <- summary(allMods)
print(xtable(perfstats), floating = FALSE)
@
\caption{\label{tab:mod-cal-stats} Performance statistics for a set of models. }
\end{center}
\end{table}


\begin{figure}[hpbt]
\begin{center}
<<mod-1990s-summary-table-code, echo=TRUE>>=
summary(simAll, breaks = "5 years")
@
\caption{Viewing a break-down the performance of a model over 5-year blocks. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot performance statistics over time:}
<<r2-breaks-plot-code, echo=TRUE, results=hide>>=
twoYrStats <- summary(simAll, breaks = "2 years")
statSeries <- twoYrStats[,c("r.squared", "r.sq.sqrt", "rel.bias", "runoff")]
## cut off crazy R Squared values below 0 (for plotting)
statSeries[,1:2] <- pmax(statSeries[,1:2], 0)
c(xyplot(statSeries, type = "s", lwd = 2,
         ylab = "statistic", xlab = NULL),
  `observed streamflow` = xyplot(observed(simAll)),
  layout = c(1,5), x.same = TRUE) +
    layer_(panel.refline(v = time(statSeries), h = 0))
@
<<r2-breaks-plot, fig=TRUE, height=7>>=
print(trellis.last.object())
@
\caption{\label{fig:r2-breaks-plot} Performance statistics
  plotted over time in regular 2 year blocks. The runoff coefficient and
  observed streamflow data are also shown. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot the flow duration curve for modelled vs observed
    data in the calibration period:}
<<fdc-1-plot-code, echo=TRUE, eval=FALSE>>=
qqmath(cotterFit, scales = list(y = list(log = TRUE)), type = c("l","g"))
@
  \emph{To plot a flow duration curve for each of the simulated models:}
<<fdc-plot-code, echo=TRUE, results=hide>>=
qqmath(allMods, type = c("l","g"), 
       scales = list(y = list(log = TRUE)),
       xlab = "Standard normal variate",
       ylab = "Flow (mm/day)", 
       f.value = ppoints(100), tails.n = 50,
       as.table = TRUE)
@
<<fdc-plot, fig=TRUE, height=7>>=
print(trellis.last.object())
@
\caption{\label{fig:fdc-plot} Log-normal Daily Flow Duration Curve for models in
  simulation. }
\end{center}
\end{figure}


\section{Model and Calibration Options}

There are several extensions to the basic model used so far. With
different types of data, such as very dry or wet catchments, sub-daily
time steps, poor areal rainfall estimates, cases of baseflow loss to
groundwater, etc, different models or calibration methods will need to
be used.


\subsection{Model Structure and Parameter Ranges}

We have used an \ihacres{} CWI model in this tutorial, which is a
simple metric type model. Other SMA models are included in the
package, or one can define a new model. See the user manual for details.

Ranges of parameters to search when calibrating the effective rainfall
model can be specified as arguments to the \code{hydromad} or
\code{update()} functions. Alternatively, parameters can be fixed to a
given value by specifying a single number.

The default ranges can be seen, and set, using the function
\code{hydromad.options()}. 

The example, in the CWI model, the threshold parameter \code{l} (used
for intermittent or ephemeral rivers), defaults to a fixed value of
0. To allow calibration of this parameter, specify a numerical
range. Similarly, the temperature dependence parameter \code{f}
defaults to the range $[0,8]$; to fix it to a given value, just
specify it:

<<echo=TRUE, eval=FALSE>>=
hydromad(ts90s, sma = "cwi", l = c(0, 200), f = 0)
@

\subsection{Optimisation settings}

Each of the fitting functions has several options, and the help pages
should be consulted for details. An important option is the choice of
objective function; see the discussion above about how to specify it.

In the simple cases of using \code{fitBySampling} or
\code{fitByOptim}, the argument \code{samples} specifies how many
random parameter sets will be sampled (from the predefined parameter
ranges), and argument \code{sampletype} chooses Uniform Random, Latin
Hypercube, or ``all combinations'' (a regular grid of values). The one
model with best objective function value is chosen. In the case of
\code{fitByOptim} this is then improved locally with an optimisation
algorithm.


\subsection{Transfer Function Order}

When using \code{armax} or \code{expuh} routing, the order of the
transfer function may be varied, as well as the delay time. If there
is any ambiguity in choosing the best delay time, each possibility
should be tried. 

A recommended approach is to begin with a simple model, say a first
order model $(n=1, m=0)$, then test whether a more complex model leads
to substantial improvement. Complex models often can not be well
identified from observed data; in this case the calibration may fail
to converge, or may converge to a physically unreasonable parameter set.

To test different model structures systematically, a convenience
function \code{tryModelOrders} is provided. An example is given in
Table \ref{tab:try-model-orders}. In this case a simple SMA is used,
called \code{runoffratio}, where the effective rainfall is the
rainfall scaled by the runoff coefficient calculated in a moving
window of 30 time steps.\footnote{To increase smoothness, actually a
triangular filter is used with the same effective width as a moving
average of width 30; see the help page \code{?runoffratio.sim}.}

For more information on these issues see, for example,
Jakeman et. al. (1990) and Young (2003).

\begin{table}[hpbt]
\begin{center}
<<try-model-orders-table-code, echo=TRUE, results=hide>>=
ihSpec <- hydromad(ts90s, sma = "runoffratio", width = 30, kernel = 2,
                   rrthresh = 0, routing = "armax")
osumm <- tryModelOrders(update(ihSpec, rfit = "sriv"),
                        n = 0:3, m = 0:3, delay = 0)
summary(osumm)
@
<<try-model-orders-table, results=tex>>=
perfstats <- summary(osumm)
print(xtable(perfstats), floating = FALSE)
@
\caption{\label{tab:try-model-orders}
  Fit and information statistics from fitting different unit
  hydrograph transfer functions with SRIV algorithm. The effective
  rainfall input was generated by a simple runoff coefficient model. }
\end{center}
\end{table}


\subsection{Unit Hydrograph Fitting Methods}

Unit Hydrograph routing models are typically fitted using least
squares or SRIV algorithms. One alternative is to fit the unit
hydrograph to the observed streamflow data -- though usually
constrained by rainfall -- and then use that as a fixed component
while calibrating the effective rainfall model. This can be done with
\code{rfit = list("inverse", ...)}. (There are many options here also).

Another option is to fit the rouing parameters together with the SMA
parameters, by specifying ranges of values for each, just like the
other parameters. This will work with the general fitting functions
(\code{fitBySCE}, etc). A typical specification for a second-order
Unit Hydrograph is:
\code{hydromad(..., routing = "expuh", 
      tau_s = c(5,100), tau_q = c(0,5), v_s = c(0,1))}.


\subsection{Other Options}

If model calibration is failing, you can set
\code{hydromad.options(trace = TRUE)} and/or
\code{hydromad.options(catch.errors = FALSE)} to track down what is
happening.

It is sometimes useful to look at the model state variables, available
as \code{predict(mod, return\_state = TRUE)} (for the SMA model), or
\code{predict(mod, return\_components = TRUE)} (for the routing
model), to see if they look sensible.

Some other things to try are
\begin{itemize}
  \item using different calibration periods;
  \item changing the warmup period length;
  \item changing the optimisation method and/or settings.
\end{itemize}


\section{What Next?}

This document has described only a basic model fitting process.

%An overview of the available models and options is given in the user
%manual, which can be accessed as \code{vignette("hydromad")}.

Help pages are available for most functions, and these are also
available online at \url{http://hydromad.catchment.org/}. There is also
a set of demos: see \code{demo(package = "hydromad")} for a list.

Please discuss any problems or suggestions with the package maintainer.


\section*{Computational details}

The results in this paper were obtained using \proglang{R}
\Sexpr{paste(R.Version()[6:7], collapse = ".")} with the packages
\pkg{hydromad} \Sexpr{gsub("-", "--", packageDescription("hydromad")$Version)},
\pkg{zoo} \Sexpr{gsub("-", "--", packageDescription("zoo")$Version)} and
\pkg{latticeExtra} \Sexpr{gsub("-", "--", packageDescription("latticeExtra")$Version)}.
\proglang{R} itself and all packages used are (or will be) available from
CRAN at \code{http://CRAN.R-project.org/}.


\end{document}
